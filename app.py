import streamlit as st
import os
import tempfile
from ingest import ingest_document
from query import retrieve_and_answer

# Page config
st.set_page_config(
    page_title="RAG Chatbot",
    page_icon="ü§ñ",
    layout="wide"
)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

def main():
    st.title("ü§ñ RAG Chatbot - H·ªá th·ªëng H·ªèi ƒê√°p Th√¥ng Minh")
    st.markdown("---")
    
    # Sidebar for file upload
    with st.sidebar:
        st.header("üìÅ Upload T√†i li·ªáu")
        
        uploaded_files = st.file_uploader(
            "Ch·ªçn file t√†i li·ªáu",
            type=['pdf', 'docx', 'txt', 'md', 'markdown', 'xlsx', 'xls', 'pptx', 'html', 'htm', 'json', 'csv'],
            accept_multiple_files=True,
            help="H·ªó tr·ª£: PDF, DOCX, TXT, MD, XLSX, PPTX, HTML, JSON, CSV"
        )
        
        if uploaded_files:
            st.write(f"ƒê√£ ch·ªçn {len(uploaded_files)} file(s)")
            
            if st.button("üöÄ X·ª≠ l√Ω v√† L∆∞u tr·ªØ", type="primary"):
                with st.spinner("ƒêang x·ª≠ l√Ω t√†i li·ªáu..."):
                    for uploaded_file in uploaded_files:
                        try:
                            # Save uploaded file temporarily
                            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                                tmp_file.write(uploaded_file.getvalue())
                                tmp_file_path = tmp_file.name
                            
                            # Ingest document
                            doc_id = ingest_document(tmp_file_path)
                            
                            # Clean up temp file
                            os.unlink(tmp_file_path)
                            
                            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {uploaded_file.name} (ID: {doc_id[:8]}...)")
                            
                        except Exception as e:
                            st.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_file.name}: {str(e)}")
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üí¨ Chat v·ªõi AI")
        
        # Chat input
        user_question = st.text_area(
            "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
            placeholder="V√≠ d·ª•: N·ªôi dung ch√≠nh c·ªßa t√†i li·ªáu l√† g√¨?",
            height=100
        )
        
        # Advanced options
        with st.expander("‚öôÔ∏è T√πy ch·ªçn n√¢ng cao"):
            top_k = st.slider("S·ªë l∆∞·ª£ng ngu·ªìn tham kh·∫£o:", 3, 20, 10)
            
            # File type filter
            file_types = ["T·∫•t c·∫£", "PDF", "DOCX", "TXT", "MD", "XLSX", "JSON", "CSV", "HTML"]
            selected_file_type = st.selectbox("L·ªçc theo lo·∫°i file:", file_types)
        
        if st.button("üîç T√¨m ki·∫øm v√† Tr·∫£ l·ªùi", type="primary") and user_question:
            with st.spinner("ƒêang t√¨m ki·∫øm v√† t·∫°o c√¢u tr·∫£ l·ªùi..."):
                try:
                    result = retrieve_and_answer(user_question, top_k)
                    
                    # Add to chat history
                    st.session_state.chat_history.append({
                        "question": user_question,
                        "answer": result["answer"],
                        "sources": result["sources"],
                        "total_sources": result["total_sources"]
                    })
                    
                    # Display answer
                    st.subheader("ü§ñ C√¢u tr·∫£ l·ªùi:")
                    st.write(result["answer"])
                    
                    # Display sources with enhanced info
                    if result["sources"]:
                        st.subheader(f"üìö Ngu·ªìn tham kh·∫£o ({result['total_sources']} ngu·ªìn):")
                        for source in result["sources"]:
                            with st.expander(f"üìÑ #{source['rank']} - {source['source']} ({source['file_type'].upper()})"):
                                col_a, col_b = st.columns([3, 1])
                                with col_a:
                                    st.write(f"**N·ªôi dung:** {source['content']}")
                                with col_b:
                                    st.write(f"**Trang:** {source['page']}")
                                    if source['score']:
                                        st.write(f"**ƒê·ªô li√™n quan:** {source['score']:.3f}")
                                    st.write(f"**K√≠ch th∆∞·ªõc:** {source['file_size']} bytes")
                                    st.write(f"**Processor:** {source['processor_type']}")
                                    st.write(f"**Chunk size:** {source['chunk_size']}")
                                    st.write(f"**Chunk overlap:** {source['chunk_overlap']}")
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói: {str(e)}")
    
    with col2:
        st.header("üìã L·ªãch s·ª≠ Chat")
        
        if st.session_state.chat_history:
            for i, chat in enumerate(reversed(st.session_state.chat_history)):
                with st.expander(f"üí¨ {chat['question'][:50]}..."):
                    st.write(f"**C√¢u h·ªèi:** {chat['question']}")
                    st.write(f"**Tr·∫£ l·ªùi:** {chat['answer']}")
                    st.write(f"**S·ªë ngu·ªìn:** {chat['total_sources']}")
                    
                    # Show file types used
                    if chat['sources']:
                        file_types = list(set([s['file_type'] for s in chat['sources']]))
                        st.write(f"**Lo·∫°i file:** {', '.join(file_types)}")
        else:
            st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ chat")
        
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠"):
            st.session_state.chat_history = []
            st.rerun()
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            <p>ü§ñ RAG Chatbot - H·ªá th·ªëng H·ªèi ƒê√°p Th√¥ng Minh d·ª±a tr√™n T√†i li·ªáu</p>
            <p>S·ª≠ d·ª•ng OpenAI GPT-4o-mini v√† text-embedding-3-small</p>
            <p>Powered by Haystack Framework v·ªõi specialized components</p>
            <p>üìä Specialized processing cho t·ª´ng lo·∫°i file: PDF, DOCX, XLSX, JSON, CSV, HTML</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
