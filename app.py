# -*- coding: utf-8 -*-
"""
ğŸ¤– Hybrid RAG Chatbot with Image Support
========================================

ğŸ“‹ MÃ´ táº£: á»¨ng dá»¥ng RAG chatbot hybrid vá»›i Haystack + LangChain fallback
ğŸ¯ Má»¥c Ä‘Ã­ch: Xá»­ lÃ½ tÃ i liá»‡u Ä‘a Ä‘á»‹nh dáº¡ng vÃ  chat tÆ°Æ¡ng tÃ¡c
ğŸ”§ Architecture: Hybrid approach vá»›i auto-fallback cho reliability cao

ğŸ“Š Luá»“ng Ä‘i chÃ­nh:
1. ğŸš€ Initialization: Load services, NLTK data, chat history
2. ğŸ“ File Management: Upload, process, auto-reload documents
3. ğŸ’¬ Chat Interface: Process queries vá»›i Hybrid RAG pipeline
4. ğŸ–¼ï¸ Image Support: Extract vÃ  display relevant images
5. ğŸ’¾ Persistence: Save chat history vÃ  session state

ğŸ”§ Key Components:
- @st.cache_resource: Cache services Ä‘á»ƒ performance
- @lru_cache: Cache chat history Ä‘á»ƒ trÃ¡nh re-reading
- Session State: Quáº£n lÃ½ UI state vÃ  user data
- Error Handling: Graceful degradation vá»›i fallback
- File Processing: Multi-format support vá»›i DocumentService

ğŸ“ˆ Performance Optimizations:
- Caching strategies cho services vÃ  data
- Lazy loading cho documents
- Pagination cho file lists
- Smart search vÃ  filtering
- Memory efficient processing

ğŸ”„ Hybrid Pipeline Logic:
- Primary: Haystack Core (fast, feature-rich)
- Fallback: LangChain (reliable, simple)
- Auto-switch: Exception-based fallback
- Unified: Consistent result format

ğŸ“ File Structure:
- uploads/: Stored uploaded files
- image_database/: Extracted images
- chat_history.json: Persistent chat data
- Session state: Runtime data management

ğŸ¨ UI Features:
- Smart file list vá»›i search vÃ  pagination
- File type icons vÃ  truncation
- Real-time chat interface
- Image display vá»›i download
- Progress indicators vÃ  error handling
"""

import streamlit as st
import os
import json
import logging
from datetime import datetime
from typing import List, Dict, Any
from functools import lru_cache

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
from dotenv import load_dotenv

load_dotenv()

# Import all services at top level for better performance
from app_factory import initialize_app, get_app_factory
from services.document_service import DocumentService

# Download NLTK data once at startup
try:
    import nltk
    import ssl

    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Global constants
CHAT_HISTORY_FILE = "chat_history.json"
UPLOADS_DIR = "uploads"
MAX_FILENAME_LENGTH = 25


def download_nltk_data():
    """
    ğŸ“š Download required NLTK data for markdown processing

    ğŸ”„ Luá»“ng Ä‘i:
    1. Download punkt: Sentence tokenization
    2. Download averaged_perceptron_tagger: POS tagging
    3. Download maxent_ne_chunker: Named entity recognition
    4. Download words: Word list
    5. Download stopwords: Stop words removal

    ğŸ“Š Má»¥c Ä‘Ã­ch: Há»— trá»£ xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh
    """
    try:
        nltk.download("punkt", quiet=True)
        nltk.download("averaged_perceptron_tagger", quiet=True)
        nltk.download("maxent_ne_chunker", quiet=True)
        nltk.download("words", quiet=True)
        nltk.download("stopwords", quiet=True)
        return True
    except Exception as e:
        st.warning(f"âš ï¸ Warning: Could not download NLTK data: {e}")
        return False


@lru_cache(maxsize=1)
def load_chat_history() -> List[Dict[str, Any]]:
    """
    ğŸ“š Load chat history tá»« JSON file vá»›i caching

    ğŸ”„ Luá»“ng Ä‘i:
    1. Check file tá»“n táº¡i
    2. Load JSON vá»›i UTF-8 encoding
    3. Cache result Ä‘á»ƒ trÃ¡nh re-reading
    4. Return empty list náº¿u file khÃ´ng tá»“n táº¡i

    ğŸ“Š Performance: @lru_cache(maxsize=1) Ä‘á»ƒ cache result
    ğŸ’¾ Persistence: UTF-8 encoding cho Vietnamese text
    """
    try:
        if os.path.exists(CHAT_HISTORY_FILE):
            with open(CHAT_HISTORY_FILE, "r", encoding="utf-8") as f:
                history = json.load(f)
                return history
        else:
            return []
    except Exception as e:
        logger.error(f"âŒ Error loading chat history: {e}")
        return []


def save_chat_history(chat_history: List[Dict[str, Any]]) -> None:
    """
    ğŸ’¾ Save chat history vÃ o JSON file

    ğŸ”„ Luá»“ng Ä‘i:
    1. Write JSON vá»›i UTF-8 encoding
    2. Clear cache Ä‘á»ƒ force reload
    3. Log success/failure

    ğŸ“Š Format: JSON vá»›i ensure_ascii=False cho Vietnamese
    ğŸ”„ Cache: Clear cache sau khi save Ä‘á»ƒ consistency
    """
    try:
        with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(chat_history, f, ensure_ascii=False, indent=2)
        # Clear cache to force reload
        load_chat_history.cache_clear()
    except Exception as e:
        logger.error(f"âŒ Error saving chat history: {e}")


@st.cache_data(ttl=3600)  # Cache for 1 hour
def get_uploaded_files() -> List[str]:
    """
    ğŸ“ Get list of uploaded files vá»›i caching

    ğŸ”„ Luá»“ng Ä‘i:
    1. Check uploads directory tá»“n táº¡i
    2. List all files trong directory
    3. Filter chá»‰ files (khÃ´ng folders)
    4. Cache result cho 1 hour

    ğŸ“Š Performance: @st.cache_data(ttl=3600) Ä‘á»ƒ cache 1 giá»
    ğŸ” Purpose: TrÃ¡nh re-scanning directory má»—i láº§n
    """
    if not os.path.exists(UPLOADS_DIR):
        return []

    files = [
        f
        for f in os.listdir(UPLOADS_DIR)
        if os.path.isfile(os.path.join(UPLOADS_DIR, f))
    ]
    return files


def auto_reload_documents(rag_pipeline, image_database):
    """Auto-reload documents from uploads folder with minimal logging"""
    if not os.path.exists(UPLOADS_DIR):
        return

    files = [
        f
        for f in os.listdir(UPLOADS_DIR)
        if os.path.isfile(os.path.join(UPLOADS_DIR, f))
    ]

    if not files:
        return

    # Suppress ALL detailed logging
    import logging

    original_level = logging.getLogger().level
    logging.getLogger().setLevel(logging.CRITICAL)  # Only critical errors

    try:
        for file_name in files:
            file_path = os.path.join(UPLOADS_DIR, file_name)

            # Process document silently
            documents = DocumentService().convert_file(file_path)
            if documents and rag_pipeline and hasattr(rag_pipeline, "add_documents"):
                rag_pipeline.add_documents(documents)

                # Extract images silently
                try:
                    image_database.extract_images_from_any_file(file_path, file_name)
                except:
                    pass  # Silently ignore image extraction errors

                # Update session state
                if "processed_files" not in st.session_state:
                    st.session_state.processed_files = []
                if file_name not in st.session_state.processed_files:
                    st.session_state.processed_files.append(file_name)

        # Only show final success message
        logger.info(f"âœ… Loaded {len(files)} documents")

    finally:
        # Restore logging level
        logging.getLogger().setLevel(original_level)


@st.cache_resource
def initialize_services():
    """
    ğŸ”§ Initialize services vá»›i caching cho performance tá»‘i Æ°u

    ğŸ”„ Luá»“ng Ä‘i:
    1. Gá»i initialize_app() tá»« app_factory
    2. Láº¥y AppFactory instance
    3. Cache result Ä‘á»ƒ trÃ¡nh re-initialization
    4. Return factory Ä‘á»ƒ access services

    ğŸ“Š Performance: @st.cache_resource Ä‘á»ƒ cache services
    ğŸ”„ Purpose: TrÃ¡nh re-initializing services má»—i láº§n
    """
    initialize_app()
    app_factory = get_app_factory()
    return app_factory


def debug_session_state():
    """Debug session state with minimal output"""
    # Only log if there are issues
    if not st.session_state.get("processed_files"):
        logger.info("ğŸ“„ No files in session state")

    # Only show files in uploads dir if needed for debugging
    if os.path.exists(UPLOADS_DIR):
        files = [
            f
            for f in os.listdir(UPLOADS_DIR)
            if os.path.isfile(os.path.join(UPLOADS_DIR, f))
        ]
        if not files:
            logger.info("ğŸ“ Uploads directory is empty")


def test_text_processing():
    """
    ğŸ” Test text processing functions directly
    """
    from services.rag_pipeline import TextProcessor

    test_query = "OKVIP - TUYá»‚N Dá»¤NG IT DEV"
    test_content = "OKVIP - TUYá»‚N Dá»¤NG IT DEV (APP DEVELOPER) MÃ” Táº¢ CÃ”NG VIá»†C: THAM GIA PHÃT TRIá»‚N VÃ€ Báº¢O TRÃŒ á»¨NG Dá»¤NG DI Äá»˜NG"

    st.write("ğŸ” Text Processing Test:")
    st.write(f"Original query: '{test_query}'")
    st.write(f"Original content: '{test_content}'")

    # Test normalization
    normalized_query = TextProcessor.normalize_text(test_query)
    normalized_content = TextProcessor.normalize_text(test_content)

    st.write(f"Normalized query: '{normalized_query}'")
    st.write(f"Normalized content: '{normalized_content}'")

    # Test search variations
    variations = TextProcessor.create_search_variations(test_query)
    st.write(f"Search variations: {variations}")

    # Test matching
    matches = []
    for variation in variations:
        if variation in normalized_content:
            matches.append(variation)

    st.write(f"Matches found: {matches}")

    return matches


def main():
    """
    ğŸš€ Main application function - Khá»Ÿi táº¡o vÃ  quáº£n lÃ½ toÃ n bá»™ á»©ng dá»¥ng

    ğŸ”„ Luá»“ng Ä‘i:
    1. Initialize services vá»›i caching (@st.cache_resource)
    2. Download NLTK data má»™t láº§n duy nháº¥t
    3. Load chat history tá»« file JSON
    4. Auto-reload documents tá»« uploads folder
    5. Render UI components:
       - Sidebar vá»›i file management
       - Main content vá»›i chat interface
       - File upload section
       - Chat history display

    ğŸ“Š Session State Management:
    - chat_history: Chat messages
    - processed_files: Uploaded files
    - auto_reloaded: Auto-reload flag
    - force_show_upload: Show upload area
    - show_all_files: File list pagination
    - last_displayed_images: Last shown images
    - file_search: File search term

    ğŸ¨ UI Components:
    - Smart file list vá»›i search vÃ  pagination
    - File type icons vÃ  truncation
    - Real-time chat interface
    - Image display vá»›i download
    - Progress indicators vÃ  error handling
    """
    # Initialize services with caching
    app_factory = initialize_services()

    # Download NLTK data once
    download_nltk_data()

    # Initialize chat history from file if not in session state
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = load_chat_history()

    # Get services from AppFactory
    rag_pipeline = app_factory.get_rag_pipeline()
    image_database = app_factory.get_image_database()
    config = app_factory.get_config()

    # Debug session state
    debug_session_state()

    # Auto-reload documents if not already done
    if not st.session_state.get("auto_reloaded", False):
        if rag_pipeline:
            auto_reload_documents(rag_pipeline, image_database)
        st.session_state.auto_reloaded = True

    # Display files in sidebar (no logging needed)
    if st.session_state.get("processed_files"):
        pass  # Files will be displayed in sidebar

    # Sidebar
    with st.sidebar:
        st.title("âš™ï¸ CÃ i Ä‘áº·t")

        # Show uploaded files list with scrollable container
        if st.session_state.get("processed_files"):
            st.subheader("ğŸ“„ Files")

            # Add search/filter for files
            search_term = st.text_input(
                "ğŸ” TÃ¬m file...", placeholder="Nháº­p tÃªn file", key="file_search"
            )

            # Filter files based on search
            files_to_show = st.session_state.processed_files
            if search_term:
                files_to_show = [
                    f for f in files_to_show if search_term.lower() in f.lower()
                ]

            # Show file count
            st.caption(
                f"ğŸ“Š {len(files_to_show)}/{len(st.session_state.processed_files)} files"
            )

            # Scrollable container for files
            with st.container():
                # Limit display to first 10 files, show more button if needed
                max_display = 10
                files_display = files_to_show[:max_display]

                for i, file_name in enumerate(files_display):
                    # Truncate long filenames
                    display_name = file_name
                    if len(file_name) > 25:
                        display_name = file_name[:20] + "..." + file_name[-4:]

                    # Add file type icon
                    file_ext = (
                        file_name.split(".")[-1].lower() if "." in file_name else "txt"
                    )
                    icon_map = {
                        "pdf": "ğŸ“„",
                        "docx": "ğŸ“",
                        "xlsx": "ğŸ“Š",
                        "pptx": "ğŸ“ˆ",
                        "txt": "ğŸ“ƒ",
                        "md": "ğŸ“‹",
                        "json": "ğŸ“‹",
                        "csv": "ğŸ“Š",
                    }
                    icon = icon_map.get(file_ext, "ğŸ“„")

                    st.write(f"{icon} {display_name}")

                # Show "more files" button if needed
                if len(files_to_show) > max_display:
                    if st.button(
                        f"ğŸ“‹ Xem thÃªm {len(files_to_show) - max_display} files...",
                        key="show_more_files",
                    ):
                        st.session_state.show_all_files = True
                        st.rerun()

                # Show all files if requested
                if st.session_state.get("show_all_files", False):
                    st.write("---")
                    for file_name in files_to_show[max_display:]:
                        display_name = file_name
                        if len(file_name) > 25:
                            display_name = file_name[:20] + "..." + file_name[-4:]
                        file_ext = (
                            file_name.split(".")[-1].lower()
                            if "." in file_name
                            else "txt"
                        )
                        icon = icon_map.get(file_ext, "ğŸ“„")
                        st.write(f"{icon} {display_name}")

                    if st.button("ğŸ“‹ Thu gá»n", key="collapse_files"):
                        st.session_state.show_all_files = False
                        st.rerun()
        else:
            st.write("ğŸ“„ No files uploaded")

        # Add new file button
        if st.button("ğŸ“ ThÃªm file má»›i", type="primary"):
            st.session_state.force_show_upload = True
            st.rerun()

        # Delete all files button
        if st.session_state.get("processed_files"):
            if st.button(
                "ğŸ—‘ï¸ XÃ³a háº¿t file",
                type="secondary",
                help="XÃ³a táº¥t cáº£ files khá»i database vÃ  uploads",
            ):
                # Clear files from database
                if rag_pipeline:
                    rag_pipeline.clear_documents()

                # Clear files from uploads folder
                import shutil

                if os.path.exists(UPLOADS_DIR):
                    shutil.rmtree(UPLOADS_DIR)
                    os.makedirs(UPLOADS_DIR)

                # Clear session state
                st.session_state.processed_files = []
                st.session_state.auto_reloaded = False

                st.success("âœ… ÄÃ£ xÃ³a háº¿t files!")
                st.rerun()

        # Clear chat button
        if st.session_state.get("chat_history"):
            if st.button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­ chat", type="secondary"):
                st.session_state.chat_history = []
                save_chat_history([])
                st.rerun()

        # Debug button
        if st.button("ğŸ” Debug Session", type="secondary", help="Debug session state"):
            st.write("ğŸ” Debug Info:")
            st.write(
                f"- processed_files: {st.session_state.get('processed_files', 'NOT SET')}"
            )
            st.write(
                f"- auto_reloaded: {st.session_state.get('auto_reloaded', 'NOT SET')}"
            )
            st.write(
                f"- force_show_upload: {st.session_state.get('force_show_upload', 'NOT SET')}"
            )

            if os.path.exists(UPLOADS_DIR):
                files = os.listdir(UPLOADS_DIR)
                st.write(f"- Files in uploads dir: {files}")
            else:
                st.write("- Uploads directory does not exist")

        # Debug RAG Pipeline button
        if st.button(
            "ğŸ” Debug RAG Pipeline", type="secondary", help="Debug RAG pipeline search"
        ):
            if rag_pipeline:
                st.write("ğŸ” RAG Pipeline Debug:")

                # Test direct search
                test_query = "OKVIP - TUYá»‚N Dá»¤NG IT DEV"
                st.write(f"Testing query: '{test_query}'")

                # Get all documents
                try:
                    all_docs = rag_pipeline.document_store.get_all_documents()
                    st.write(f"Total documents in store: {len(all_docs)}")

                    # Show first few documents
                    for i, doc in enumerate(all_docs[:3]):
                        st.write(f"Document {i+1}:")
                        st.write(f"Content: {doc.content[:300]}...")
                        st.write(f"Meta: {doc.meta}")
                        st.write("---")

                    # Test direct retrieval
                    try:
                        if hasattr(rag_pipeline.retriever, "retrieve"):
                            retrieved = rag_pipeline.retriever.retrieve(test_query)
                            st.write(f"Retrieved documents: {len(retrieved)}")
                            for i, doc in enumerate(retrieved[:2]):
                                st.write(f"Retrieved {i+1}: {doc.content[:200]}...")
                    except Exception as e:
                        st.error(f"Error debugging RAG: {e}")
                except Exception as e:
                    st.error(f"Error debugging RAG: {e}")
        else:
            st.error("RAG Pipeline not available")

        # Test Text Processing button
        if st.button(
            "ğŸ” Test Text Processing",
            type="secondary",
            help="Test text processing functions",
        ):
            test_text_processing()

        # Force Reload Documents button
        if st.button(
            "ğŸ”„ Force Reload Documents",
            type="secondary",
            help="Force clear and reload all documents",
        ):
            if rag_pipeline:
                # Clear documents
                rag_pipeline.clear_documents()
                st.success("âœ… Cleared documents")

                # Clear session state
                st.session_state.processed_files = []
                st.session_state.auto_reloaded = False

                # Reload documents
                auto_reload_documents(rag_pipeline, image_database)
                st.session_state.auto_reloaded = True

                st.success("âœ… Documents reloaded!")
                st.rerun()
            else:
                st.error("RAG Pipeline not available")

        # Reset session button
        if st.button(
            "ğŸ”„ Reset Session", type="secondary", help="Reset all session state"
        ):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.success("âœ… Session state reset!")
            st.rerun()

    # Main content area
    st.title("ğŸ¤– Hybrid RAG Chatbot")
    st.markdown("**Hybrid RAG Pipeline vá»›i Haystack Core + LangChain Fallback**")

    # Show files summary when files exist
    if st.session_state.get("processed_files"):
        st.subheader("ğŸ“š Documents Ready")
        st.success(
            f"âœ… {len(st.session_state.processed_files)} documents loaded and ready for chat!"
        )

    # Chat interface
    st.subheader("ğŸ’¬ Chat")

    # Display chat history
    if st.session_state.get("chat_history"):
        for message in st.session_state.chat_history:
            with st.chat_message("user"):
                st.write(message["question"])
            with st.chat_message("assistant"):
                st.write(message["answer"])
                if message.get("sources"):
                    with st.expander("ğŸ“š Nguá»“n tham kháº£o"):
                        for source in message["sources"]:
                            st.write(f"ğŸ“„ {source}")

    # Chat input
    prompt = st.chat_input("Ask anything...")

    # Process chat input
    if prompt:
        if rag_pipeline is None:
            st.error(
                "âŒ RAG Pipeline khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng kiá»ƒm tra cÃ i Ä‘áº·t Haystack."
            )
        else:
            process_chat_input_old(prompt, rag_pipeline, image_database)

    # File upload section - Only show when no files or force show
    has_files = bool(st.session_state.get("processed_files"))
    force_show = st.session_state.get("force_show_upload", False)

    if not has_files or force_show:
        st.subheader("ğŸ“ Upload Documents")
        st.info(
            "ğŸ’¡ Upload documents Ä‘á»ƒ chat vá»›i AI. Há»— trá»£: PDF, DOCX, TXT, MD, XLSX, CSV, HTML, JSON"
        )

        uploaded_files = st.file_uploader(
            "Choose files",
            type=config.processing.supported_formats,
            accept_multiple_files=True,
            help="PDF, DOCX, TXT, MD, MARKDOWN, XLSX, XLS, PPTX, HTML, HTM, JSON, CSV",
        )

        if uploaded_files:
            # Process uploaded files
            process_uploaded_files_old(uploaded_files, rag_pipeline, image_database)

            # Hide upload area after processing
            st.session_state.force_show_upload = False
            st.rerun()


def fix_double_extension(filename: str) -> str:
    """
    ğŸ”§ Fix common double extension issues

    ğŸ”„ Luá»“ng Ä‘i:
    1. Define extensions mapping
    2. Check filename cÃ³ double extension
    3. Replace vá»›i single extension
    4. Return fixed filename

    ğŸ“Š Purpose: Xá»­ lÃ½ lá»—i upload file cÃ³ double extension
    ğŸ” Common cases: .pdf.pdf, .docx.docx, .xlsx.xlsx, .md.md
    """
    extensions_map = {
        ".pdf.pdf": ".pdf",
        ".docx.docx": ".docx",
        ".xlsx.xlsx": ".xlsx",
        ".md.md": ".md",
    }

    for old_ext, new_ext in extensions_map.items():
        if filename.endswith(old_ext):
            return filename.replace(old_ext, new_ext)
    return filename


def save_uploaded_file(uploaded_file, uploads_dir: str) -> str:
    """
    ğŸ’¾ Save uploaded file to disk vá»›i proper error handling

    ğŸ”„ Luá»“ng Ä‘i:
    1. Create uploads directory náº¿u khÃ´ng tá»“n táº¡i
    2. Fix double extensions
    3. Generate file path
    4. Write file content
    5. Return file path

    ğŸ“Š Error Handling: Create directory náº¿u khÃ´ng tá»“n táº¡i
    ğŸ”§ File Processing: Fix double extensions trÆ°á»›c khi save
    """
    if not os.path.exists(uploads_dir):
        os.makedirs(uploads_dir)

    # Fix double extensions
    file_name = fix_double_extension(uploaded_file.name)
    file_path = os.path.join(uploads_dir, file_name)

    with open(file_path, "wb") as f:
        f.write(uploaded_file.getvalue())

    return file_path


def process_uploaded_files_old(uploaded_files, rag_pipeline, image_database) -> None:
    """Process uploaded files with enhanced error handling and status display"""
    if not uploaded_files:
        return

    # Initialize processed_files if not exists
    if "processed_files" not in st.session_state:
        st.session_state.processed_files = []

    processed_count = 0
    total_files = len(uploaded_files)

    # Create a status container
    status_container = st.empty()

    for i, uploaded_file in enumerate(uploaded_files):
        try:
            # Show simple status
            status_container.info(
                f"ğŸ”„ Äang xá»­ lÃ½: {uploaded_file.name} ({i+1}/{total_files})"
            )

            # Save file
            file_path = save_uploaded_file(uploaded_file, UPLOADS_DIR)

            # Process with document service
            documents = DocumentService().convert_file(file_path)

            if documents:
                # Add to RAG pipeline
                rag_pipeline.add_documents(documents)

                # Extract images
                images = image_database.extract_images_from_any_file(
                    file_path, uploaded_file.name
                )

                # Update session state
                if uploaded_file.name not in st.session_state.processed_files:
                    st.session_state.processed_files.append(uploaded_file.name)

                processed_count += 1

                # Show success status
                status_container.success(f"âœ… ÄÃ£ xá»­ lÃ½: {uploaded_file.name}")

                # Show image extraction status if images found
                if images:
                    status_container.info(
                        f"ğŸ–¼ï¸ ÄÃ£ trÃ­ch xuáº¥t {len(images)} áº£nh tá»« {uploaded_file.name}"
                    )

            else:
                status_container.warning(f"âš ï¸ KhÃ´ng thá»ƒ xá»­ lÃ½: {uploaded_file.name}")

        except Exception as e:
            logger.error(f"âŒ Error processing {uploaded_file.name}: {e}")
            status_container.error(f"âŒ Lá»—i xá»­ lÃ½: {uploaded_file.name}")

    # Final success message
    if processed_count > 0:
        status_container.success(f"ğŸš€ ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng {processed_count} file!")
        st.rerun()
    else:
        status_container.error("âŒ KhÃ´ng cÃ³ file nÃ o Ä‘Æ°á»£c xá»­ lÃ½ thÃ nh cÃ´ng")


def process_chat_input_old(prompt, rag_pipeline, image_database):
    """
    ğŸ’¬ Process chat input vá»›i Hybrid RAG

    ğŸ”„ Luá»“ng Ä‘i:
    1. Display user message
    2. Query RAG pipeline
    3. Display AI answer
    4. Find relevant images:
       - Extract source files tá»« documents
       - Search images by source file
       - Fallback to query-based search
    5. Display images vá»›i download buttons
    6. Show sources
    7. Save to chat history

    ğŸ¯ Hybrid Pipeline:
    - Primary: Haystack Core (fast, feature-rich)
    - Fallback: LangChain (reliable, simple)
    - Auto-switch: Exception-based fallback

    ğŸ–¼ï¸ Image Display Logic:
    - Priority 1: Images tá»« source files
    - Priority 2: Query-based image search
    - Priority 3: Images tá»« previous question
    - Limit: 1 image Ä‘á»ƒ trÃ¡nh clutter

    ğŸ’¾ Persistence:
    - Save chat history sau má»—i interaction
    - Store displayed images cho persistence
    - UTF-8 encoding cho Vietnamese text
    """
    # Hiá»ƒn thá»‹ cÃ¢u há»i cá»§a user trong chat
    st.chat_message("user").write(prompt)

    # Láº¥y cÃ¢u tráº£ lá»i tá»« AI sá»­ dá»¥ng Hybrid RAG
    with st.chat_message("assistant"):
        try:
            # Sá»­ dá»¥ng RAG pipeline Ä‘á»ƒ tÃ¬m cÃ¢u tráº£ lá»i
            result = rag_pipeline.query(prompt)

            # Display answer
            st.markdown(result["answer"], unsafe_allow_html=True)

            # Only show images if RAG found relevant information
            if "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin" not in result["answer"]:
                # TÃ¬m vÃ  hiá»ƒn thá»‹ áº£nh liÃªn quan
                relevant_images = []

                # Láº¥y source documents Ä‘á»ƒ tÃ¬m file nÃ o chá»©a cÃ¢u tráº£ lá»i
                source_docs = result.get("source_documents", [])
                source_files = set()

                for doc in source_docs:
                    # TrÃ­ch xuáº¥t tÃªn file tá»« document metadata
                    if hasattr(doc, "metadata"):
                        source_file = doc.metadata.get("source", "")
                    else:
                        # Thá»­ trÃ­ch xuáº¥t tá»« document content
                        content = str(doc)
                        import re

                        file_match = re.search(r"uploads[/\\]([^/\s]+)", content)
                        if file_match:
                            source_file = file_match.group(1)
                        else:
                            source_file = ""

                    if source_file:
                        source_files.add(source_file)

                # TÃ¬m áº£nh tá»« cÃ¹ng source files (Æ°u tiÃªn cao nháº¥t)
                for source_file in source_files:
                    images_from_source = image_database.get_images_by_source(
                        source_file
                    )
                    relevant_images.extend(images_from_source)

                # Náº¿u khÃ´ng tÃ¬m tháº¥y áº£nh tá»« source files, tÃ¬m kiáº¿m theo query
                if not relevant_images:
                    relevant_images = image_database.find_relevant_images(
                        prompt, max_results=3
                    )

                # Loáº¡i bá» trÃ¹ng láº·p vÃ  giá»›i háº¡n káº¿t quáº£
                unique_images = []
                seen_paths = set()
                for img in relevant_images:
                    if img["path"] not in seen_paths:
                        unique_images.append(img)
                        seen_paths.add(img["path"])

                # Hiá»ƒn thá»‹ áº£nh (giá»›i háº¡n 1 áº£nh Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p)
                if unique_images:
                    st.info("ğŸ–¼ï¸ **áº¢nh liÃªn quan trong tÃ i liá»‡u:**")
                    display_images = unique_images[:1]  # Chá»‰ hiá»ƒn thá»‹ 1 áº£nh

                    # Store displayed images for persistence
                    st.session_state.last_displayed_images = display_images

                    # Hiá»ƒn thá»‹ áº£nh
                    for i, img in enumerate(display_images):
                        st.image(
                            img["path"], caption=img.get("context", "")[:100] + "..."
                        )
                        with open(img["path"], "rb") as fh:
                            st.download_button(
                                "ğŸ“¥ Táº£i áº£nh",
                                fh.read(),
                                file_name=img.get("filename", "image.png"),
                                mime="image/png",
                                key=f"download_img_{i}_{img.get('filename', 'image')}",
                            )

                # Náº¿u khÃ´ng cÃ³ áº£nh má»›i, hiá»ƒn thá»‹ áº£nh tá»« cÃ¢u há»i trÆ°á»›c
                elif st.session_state.get("last_displayed_images"):
                    st.info("ğŸ–¼ï¸ **áº¢nh liÃªn quan tá»« cÃ¢u há»i trÆ°á»›c:**")
                    display_images = st.session_state.last_displayed_images[
                        :1
                    ]  # Chá»‰ 1 áº£nh
                    for i, img in enumerate(display_images):
                        st.image(
                            img["path"], caption=img.get("context", "")[:100] + "..."
                        )
                        with open(img["path"], "rb") as fh:
                            st.download_button(
                                "ğŸ“¥ Táº£i áº£nh",
                                fh.read(),
                                file_name=img.get("filename", "image.png"),
                                mime="image/png",
                                key=f"persist_img_{i}_{img.get('filename', 'image')}",
                            )
            else:
                # Clear last displayed images when no relevant info found
                if "last_displayed_images" in st.session_state:
                    del st.session_state.last_displayed_images

                    # Store sources for later display
                    sources = result.get("sources", [])
                    if sources:
                        with st.expander("ğŸ“š Nguá»“n tham kháº£o"):
                            # Lá»c vÃ  hiá»ƒn thá»‹ tÃªn file gá»‘c duy nháº¥t
                            unique_sources = []
                            for source in sources:
                                if source not in unique_sources:
                                    unique_sources.append(source)

                            for i, source in enumerate(unique_sources):
                                st.write(f"**ğŸ“„ {source}**")

                    # Add to chat history and save
                    if "chat_history" not in st.session_state:
                        st.session_state.chat_history = []

                    st.session_state.chat_history.append(
                        {
                            "question": prompt,
                            "answer": result["answer"],
                            "sources": sources,
                            "timestamp": datetime.now().isoformat(),
                        }
                    )
                    # Save chat history after each interaction
                    save_chat_history(st.session_state.chat_history)

        except Exception as e:
            st.error(f"âŒ Lá»—i: {str(e)}")


def extract_source_files(source_documents):
    """
    ğŸ“„ Extract source files tá»« documents

    ğŸ”„ Luá»“ng Ä‘i:
    1. Iterate qua source documents
    2. Extract source file tá»« metadata
    3. Fallback to content parsing náº¿u khÃ´ng cÃ³ metadata
    4. Use regex Ä‘á»ƒ extract filename tá»« path
    5. Return unique list of source files

    ğŸ“Š Purpose: TÃ¬m source files Ä‘á»ƒ image search
    ğŸ” Fallback: Parse content náº¿u metadata khÃ´ng cÃ³
    ğŸ¯ Result: List unique source files
    """
    source_files = set()

    for doc in source_documents:
        if hasattr(doc, "metadata"):
            source_file = doc.metadata.get("source", "")
        else:
            # Try to extract from document content
            content = str(doc)
            import re

            file_match = re.search(r"uploads[/\\]([^/\s]+)", content)
            if file_match:
                source_file = file_match.group(1)
            else:
                source_file = ""

        if source_file:
            source_files.add(source_file)

    return list(source_files)


if __name__ == "__main__":
    main()
